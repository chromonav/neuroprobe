{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis Using Covolutional Neural Networks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "rm -r Data\n",
    "mkdir Data\n",
    "cd Data\n",
    "kg dataset -o shashank1558 -d preprocessed-twitter-tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting word vector list to list of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datatovec(vec):\n",
    "    main = vec\n",
    "    if os.path.exists('./Models/TwitterTrain2/wordmodel'):\n",
    "        tweet_model = Word2Vec.load(\"Models/TwitterTrain2/wordmodel\")\n",
    "    else:\n",
    "        tweet_model = Word2Vec(vec, min_count=1, size=100) \n",
    "        tweet_model.save(\"Models/TwitterTrain2/wordmodel\")\n",
    "    for i,tweets in enumerate(main):\n",
    "        for j,word in enumerate(tweets):\n",
    "            main[i][j]= tweet_model.wv[word]\n",
    "    return main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    if os.path.exists('./Data/x.pickle'):\n",
    "        print(\"Pre-processed data already exists...\")\n",
    "        x = pickle.load(open(\"./Data/x.pickle\",\"rb\"))\n",
    "        y = pickle.load(open(\"./Data/y.pickle\",\"rb\"))\n",
    "    else:\n",
    "        print(\"Preprocessed data does not exist....\")\n",
    "        positive_csv = pd.read_csv(\"./Data/processedPositive.csv\")\n",
    "        negative_csv = pd.read_csv(\"./Data/processedNegative.csv\")\n",
    "        neutral_csv = pd.read_csv(\"./Data/processedNeutral.csv\")\n",
    "        for column in positive_csv:\n",
    "            x.append(text_to_word_sequence(\n",
    "            positive_csv[column].name,\n",
    "            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "            split=\" \",\n",
    "            lower=True\n",
    "        ))\n",
    "            y.append([0,0,1])\n",
    "            \n",
    "        for column in negative_csv:\n",
    "            x.append(text_to_word_sequence(\n",
    "            negative_csv[column].name,\n",
    "            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "            split=\" \",\n",
    "            lower=True\n",
    "        ))\n",
    "            y.append([1,0,0])\n",
    "            \n",
    "        for column in neutral_csv:\n",
    "            x.append(text_to_word_sequence(\n",
    "            neutral_csv[column].name,\n",
    "            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "            split=\" \",\n",
    "            lower=True\n",
    "        ))\n",
    "            y.append([0,1,0])\n",
    "        print(\"Data to vec\")\n",
    "        x = datatovec(x)\n",
    "        print(\"Padding Sequences\")\n",
    "        x  = pad_sequences(x,dtype=\"float32\")\n",
    "        y  = pad_sequences(y)\n",
    "        with open(\"./Data/x.pickle\",'wb') as f:\n",
    "            pickle.dump(x,f)\n",
    "        with open(\"./Data/y.pickle\",'wb') as f:\n",
    "            pickle.dump(y,f)\n",
    "        print(\"Data Preprocessed and Saved...\")\n",
    "        \n",
    "    data = {\n",
    "        \"x\":x,\n",
    "        \"y\":y\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "x = data[\"x\"]\n",
    "y = data[\"y\"]\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize and split data into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.03, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data and its shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Dropout,Flatten\n",
    "import keras\n",
    "model = Sequential()\n",
    "model.add(Reshape((x[0].shape[0],x[0].shape[1],1),input_shape=x[0].shape))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=x[0].shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Model\")\n",
    "model.fit(x_train, y=y_train, epochs=100, verbose=1,\n",
    "          validation_split=0.2, shuffle=True)\n",
    "madel.save(\"Trained.h5\")\n",
    "print(\"Model Trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
